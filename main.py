import feedparser
import sqlite3
import smtplib
import os
import time
import ssl
from email.mime.text import MIMEText
from email.header import Header
from datetime import datetime
from bs4 import BeautifulSoup
from openai import OpenAI

# ================= é…ç½®åŒºåŸŸ =================

# 1. ç¯å¢ƒå˜é‡
SENDER_EMAIL = os.environ.get("SENDER_EMAIL")
SENDER_PASSWORD = os.environ.get("SENDER_PASSWORD")
RECEIVER_EMAIL = os.environ.get("RECEIVER_EMAIL")
LLM_API_KEY = os.environ.get("LLM_API_KEY")
SMTP_SERVER = "smtp.qq.com"
SMTP_PORT = 465

# 2. ğŸ›¡ï¸ ã€ç™½åå•å…œåº•ã€‘ä¸­è‹±æ–‡å…³é”®è¯ (ä¸åŒºåˆ†å¤§å°å†™)
MUST_HAVE_KEYWORDS = [
    # --- English ---
    "fintech", "financial technology", 
    "machine learning", "deep learning", "neural network",
    "climate risk", "esg", "textual analysis",
    # --- ä¸­æ–‡ ---
    "é‡‘èç§‘æŠ€", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "æ–‡æœ¬åˆ†æ",
     "å¤§è¯­è¨€æ¨¡å‹", "é«˜é¢‘äº¤æ˜“", "é‡åŒ–æŠ•èµ„"
]

# 3. ğŸ¤– ã€AI åˆ¤åˆ«æ ‡å‡†ã€‘
USER_INTEREST_DESCRIPTION = """
æˆ‘çš„ç ”ç©¶å…´è¶£éå¸¸å¹¿æ³›ï¼Œè¯·é‡‡å–ã€å®½å®¹ç­–ç•¥ã€‘ï¼Œåªè¦æ–‡ç« ç¬¦åˆä»¥ä¸‹**ä»»æ„ä¸€ä¸ª**æ–¹å‘ï¼Œéƒ½å›ç­” Yesï¼š

1. **é‡‘èç§‘æŠ€ (FinTech)**ï¼šæ¶‰åŠé«˜é¢‘äº¤æ˜“ã€å¸‚åœºå¾®è§‚ç»“æ„ã€æ”¯ä»˜ã€åŒºå—é“¾ã€æ•°å­—è´§å¸åŠè´§å¸ç†è®ºçš„ä»»ä½•è¯é¢˜ã€‚
2. **AIä¸å¤§æ•°æ®**ï¼šé‡‘èä¸­çš„æœºå™¨å­¦ä¹ ã€NLPæ–‡æœ¬åˆ†æã€æƒ…æ„Ÿåˆ†æã€é«˜ç»´æ•°æ®é¢„æµ‹ã€‚
3. **èµ„äº§å®šä»·**ï¼šè‚¡ç¥¨æ”¶ç›Šé¢„æµ‹ã€å› å­æ¨¡å‹ã€é‡åŒ–ç­–ç•¥ã€‚
4. **è®¡é‡**ï¼šå› æœæ¨æ–­æ¨¡å‹ã€è®¡é‡æ¨¡å‹ã€‚

æ³¨æ„ï¼š
- å¯¹äºä¸­æ–‡æ–‡ç« ï¼Œè¯·åŒæ ·åº”ç”¨ä¸Šè¿°æ ‡å‡†ã€‚
- å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œä»…æ ¹æ®æ ‡é¢˜åˆ¤æ–­ã€‚
"""

# 4. ğŸ“š æœŸåˆŠ RSS åˆ—è¡¨
RSS_FEEDS = {
    # === è‹±æ–‡ Top Journals ===
    "Journal of Finance": "https://onlinelibrary.wiley.com/feed/15406261/most-recent",
    "JFE": "https://www.sciencedirect.com/science/journal/0304405X/rss", 
    "RFS": "https://academic.oup.com/rss/site_5378/3126.xml",
    "JFQA": "https://www.cambridge.org/core/rss/product/id/1638F6E6C5C0F911299901594F817173",
    "Management Science": "http://pubsonline.informs.org/action/showFeed?type=etoc&feed=rss&jc=mnsc",
    "Review of Finance": "https://academic.oup.com/rss/site_5409/3133.xml",
    
    # === ä¸­æ–‡ Top Journals (via RSSHub) ===
    "ç»æµç ”ç©¶": "https://rsshub.app/cnki/journals/JJYJ",
    "ç®¡ç†ä¸–ç•Œ": "https://rsshub.app/cnki/journals/GLSJ",
    "é‡‘èç ”ç©¶": "https://rsshub.app/cnki/journals/JRYJ",
    "æ•°é‡ç»æµæŠ€æœ¯ç»æµç ”ç©¶": "https://rsshub.app/cnki/journals/SLJY",
    "ä¸­å›½å·¥ä¸šç»æµ": "https://rsshub.app/cnki/journals/GGYY",
    "ç»æµå­¦å­£åˆŠ": "https://rsshub.app/cnki/journals/JJXJ"
}

LLM_BASE_URL = "https://api.deepseek.com" 
LLM_MODEL = "deepseek-chat"
DB_FILE = "finance_journals.db"

# ================= æ ¸å¿ƒä»£ç  =================

def get_ai_judgement(title, abstract):
    if not LLM_API_KEY: return False
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
    
    prompt = f"""
    åˆ¤æ–­è¿™ç¯‡é‡‘èè®ºæ–‡æ˜¯å¦ç¬¦åˆç”¨æˆ·å…´è¶£ã€‚
    
    ã€ç”¨æˆ·å…´è¶£ã€‘ï¼š{USER_INTEREST_DESCRIPTION}
    
    ã€è®ºæ–‡æ ‡é¢˜ã€‘ï¼š{title}
    ã€è®ºæ–‡æ‘˜è¦ã€‘ï¼š{abstract}
    
    è§„åˆ™ï¼š
    1. å®å¯é”™æ€ä¸€åƒï¼Œä¸å¯æ”¾è¿‡ä¸€ä¸ªã€‚åªè¦æœ‰ä¸€ç‚¹ç‚¹ç›¸å…³æ€§ï¼Œå°±å›ç­” "Yes"ã€‚
    2. å¯¹äºä¸­æ–‡æ ‡é¢˜ï¼Œè¯·ç†è§£å…¶è¯­ä¹‰ã€‚
    3. åªå›ç­” "Yes" æˆ– "No"ã€‚
    """
    try:
        response = client.chat.completions.create(
            model=LLM_MODEL, messages=[{"role": "user", "content": prompt}],
            temperature=0.1, max_tokens=5
        )
        return "yes" in response.choices[0].message.content.strip().lower()
    except:
        return False

def clean_html(raw):
    if not raw: return ""
    text = BeautifulSoup(raw, "html.parser").get_text(separator=' ')
    return ' '.join(text.split())

def init_db():
    conn = sqlite3.connect(DB_FILE)
    conn.execute('''CREATE TABLE IF NOT EXISTS articles (link TEXT PRIMARY KEY, title TEXT, journal TEXT, published_date TEXT)''')
    conn.close()

def is_new(link):
    conn = sqlite3.connect(DB_FILE)
    exists = conn.execute("SELECT 1 FROM articles WHERE link=?", (link,)).fetchone()
    conn.close()
    return exists is None

def save_article(link, title, journal, pub_date):
    conn = sqlite3.connect(DB_FILE)
    conn.execute("INSERT OR IGNORE INTO articles VALUES (?, ?, ?, ?)", (link, title, journal, pub_date))
    conn.commit()
    conn.close()

def send_email(subject, html):
    if not SENDER_PASSWORD: return False
    msg = MIMEText(html, 'html', 'utf-8')
    msg['From'], msg['To'], msg['Subject'] = Header(SENDER_EMAIL), Header(RECEIVER_EMAIL), Header(subject, 'utf-8')
    try:
        s = smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT)
        s.login(SENDER_EMAIL, SENDER_PASSWORD)
        s.sendmail(SENDER_EMAIL, [RECEIVER_EMAIL], msg.as_string())
        s.quit()
        return True
    except Exception as e:
        print(f"Email Error: {e}")
        return False

def run_job():
    print("Job started...")
    monthly_data = {}
    total_new = 0
    interesting_count = 0
    pending_save = []

    # å¿½ç•¥ SSL è¯ä¹¦éªŒè¯
    if hasattr(ssl, '_create_unverified_context'):
        ssl._create_default_https_context = ssl._create_unverified_context

    # ã€æ–°å¢ã€‘ä¼ªè£…æˆ Chrome æµè§ˆå™¨ï¼Œé˜²æ­¢è¢«æ‹¦æˆª (è§£å†³ No entries é—®é¢˜)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    for journal, url in RSS_FEEDS.items():
        print(f"Checking {journal}...")
        try:
            # ä¼ å…¥ request_headers
            feed = feedparser.parse(url, request_headers=headers)
            
            if not feed.entries:
                print(f"  > Warning: No entries for {journal}")
                continue

            for entry in feed.entries[:20]: 
                title = entry.title
                link = entry.link
                date = datetime.now().strftime('%Y-%m-%d')
                if 'published' in entry:
                    try: date = entry.published[:10]
                    except: pass
                
                if is_new(link):
                    # 1. å…³é”®è¯ç™½åå•æ£€æŸ¥
                    is_match = False
                    for kw in MUST_HAVE_KEYWORDS:
                        if kw.lower() in title.lower():
                            is_match = True
                            print(f"  >>> [Keyword Match] {title[:30]}...")
                            break
                    
                    summary = clean_html(entry.get('summary') or entry.get('description'))
                    
                    # 2. AI æ£€æŸ¥
                    if not is_match:
                        print(f"  ...asking AI: {title[:30]}...")
                        is_match = get_ai_judgement(title, summary)
                        time.sleep(0.2) # é˜²æ­¢ API è¶…é€Ÿ

                    if journal not in monthly_data: monthly_data[journal] = []
                    
                    # ã€å…³é”®ä¿®å¤ã€‘è¡¥å…¨ info å­—å…¸ï¼ŒåŠ å…¥ journal å­—æ®µ
                    info = {
                        "title": title, 
                        "link": link, 
                        "date": date, 
                        "summary": summary, 
                        "is_interesting": is_match,
                        "journal": journal  # ä¹‹å‰æŠ¥é”™æ˜¯å› ä¸ºç¼ºäº†è¿™ä¸ª
                    }
                    
                    if is_match:
                        monthly_data[journal].insert(0, info)
                        interesting_count += 1
                    else:
                        monthly_data[journal].append(info)
                    
                    pending_save.append(info)
                    total_new += 1
        except Exception as e:
            print(f"Error checking {journal}: {e}")

    if total_new > 0:
        print(f"Found {total_new} articles, {interesting_count} interesting.")
        subject_icon = "ğŸ¤– " if interesting_count > 0 else ""
        
        html = f"""<html><body style="font-family:Arial;">
        <h2>ğŸ“… é¡¶åˆŠæ–‡çŒ®æ›´æ–° (ä¸­è‹±æ–‡æ··æ’)</h2>
        <div style="background:#e8f4fd;padding:10px;margin-bottom:20px;border-radius:5px;">
        <b>ç­›é€‰ç­–ç•¥ï¼š</b>åŒ…å« FinTech/æœºå™¨å­¦ä¹ /è®¡é‡ ç­‰ä¸­è‹±æ–‡å…³é”®è¯ï¼Œæˆ–ç» AI åˆ¤å®šç¬¦åˆå…´è¶£ã€‚
        </div><hr>"""
        
        for journal, arts in monthly_data.items():
            html += f"<h3 style='background:#f2f2f2;padding:10px;border-left:5px solid #0066cc;'>{journal}</h3><ul>"
            for art in arts:
                if art['is_interesting']:
                    style = "color:#d35400;font-weight:bold;font-size:1.1em;"
                    summ = f"<div style='background:#fff8f0;padding:8px;margin-top:5px;color:#555;font-size:0.9em;'>{art['summary'][:300]}...</div>"
                    icon = "ğŸ’¡"
                else:
                    style, summ, icon = "color:#0066cc;font-weight:bold;", "", ""
                
                html += f"<li style='margin-bottom:15px;'>{icon} <a href='{art['link']}' style='{style}text-decoration:none;'>{art['title']}</a><span style='color:#999;font-size:0.8em;margin-left:10px;'>{art['date']}</span>{summ}</li>"
            html += "</ul>"
        
        html += "</body></html>"

        if send_email(f"{subject_icon}æ–‡çŒ®æ›´æ–°: {interesting_count}ç¯‡ç²¾é€‰ ({total_new}ç¯‡æ–°å¢)", html):
            for art in pending_save: 
                # è¿™é‡Œç°åœ¨ä¸ä¼šæŠ¥é”™äº†
                save_article(art['link'], art['title'], art['journal'], art['date'])
            
            # è‡ªåŠ¨åŒæ­¥æ•°æ®åº“
            os.system('git config --global user.name "Bot" && git config --global user.email "bot@bot.com"')
            os.system('git add finance_journals.db && git commit -m "Update DB" && git pull --rebase origin main && git push')
    else:
        print("No new articles.")

if __name__ == "__main__":
    init_db()
    run_job()
