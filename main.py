import feedparser
import sqlite3
import smtplib
import os
import time
from email.mime.text import MIMEText
from email.header import Header
from datetime import datetime
from bs4 import BeautifulSoup
from openai import OpenAI

# ================= é…ç½®åŒºåŸŸ =================

# 1. ç¯å¢ƒå˜é‡ (GitHub Secrets)
SENDER_EMAIL = os.environ.get("SENDER_EMAIL")
SENDER_PASSWORD = os.environ.get("SENDER_PASSWORD")
RECEIVER_EMAIL = os.environ.get("RECEIVER_EMAIL")
LLM_API_KEY = os.environ.get("LLM_API_KEY")

SMTP_SERVER = "smtp.qq.com"
SMTP_PORT = 465

# 2. ğŸ¤– [æ ¸å¿ƒä¿®æ”¹] ç”¨è‡ªç„¶è¯­è¨€æè¿°ä½ çš„ç ”ç©¶å…´è¶£
# ä½ å¯ä»¥å†™å¾—å¾ˆå…·ä½“ï¼ŒAI ä¼šç†è§£å…¶ä¸­çš„æ¦‚å¿µã€åŒä¹‰è¯å’Œéšå«é€»è¾‘ã€‚
USER_INTEREST_DESCRIPTION = """
æˆ‘çš„ä¸»è¦ç ”ç©¶å…´è¶£æ˜¯é‡‘èç§‘æŠ€ï¼ˆFinTechï¼‰å’Œæœºå™¨å­¦ä¹ åœ¨èµ„äº§å®šä»·ä¸­çš„åº”ç”¨ã€‚
å…·ä½“åŒ…æ‹¬ï¼š
1. æ·±åº¦å­¦ä¹ ã€ç¥ç»ç½‘ç»œã€NLPæ–‡æœ¬åˆ†æåœ¨é¢„æµ‹è‚¡ç¥¨æ”¶ç›Šç‡ä¸­çš„åº”ç”¨ã€‚
2. å¸‚åœºå¾®è§‚ç»“æ„ä¸­çš„é«˜é¢‘äº¤æ˜“ç­–ç•¥ã€‚
3. å› æœæ¨æ–­å’Œè®¡é‡æ–¹æ³•
"""

# 3. å¤§æ¨¡å‹é…ç½® (è¿™é‡Œé»˜è®¤ä½¿ç”¨ DeepSeekï¼Œå› ä¸ºå®ƒä¾¿å®œä¸”å¼ºå¤§)
# å¦‚æœä½ æƒ³ç”¨ ChatGPTï¼ŒBase_URL æ”¹ä¸º "https://api.openai.com/v1", Model æ”¹ä¸º "gpt-4o-mini"
LLM_BASE_URL = "https://api.deepseek.com" 
LLM_MODEL = "deepseek-chat"

# 4. RSS åˆ—è¡¨
RSS_FEEDS = {
    "Journal of Finance": "https://onlinelibrary.wiley.com/feed/15406261/most-recent",
    "JFE": "https://www.sciencedirect.com/science/journal/0304405X/rss", 
    "RFS": "https://academic.oup.com/rss/site_5378/3126.xml",
    "JFQA": "https://www.cambridge.org/core/rss/product/id/1638F6E6C5C0F911299901594F817173",
    "Management Science": "http://pubsonline.informs.org/action/showFeed?type=etoc&feed=rss&jc=mnsc",
    "Review of Finance": "https://academic.oup.com/rss/site_5409/3133.xml"
}

DB_FILE = "finance_journals.db"

# ================= æ ¸å¿ƒä»£ç  =================

def get_ai_judgement(title, abstract):
    """è°ƒç”¨ LLM åˆ¤æ–­æ–‡ç« æ˜¯å¦ç¬¦åˆå…´è¶£"""
    if not LLM_API_KEY:
        print("Error: No API Key found.")
        return False

    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)
    
    # æ„é€  Prompt
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èå­¦æœ¯åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ç”¨æˆ·çš„ç ”ç©¶å…´è¶£æè¿°ï¼Œåˆ¤æ–­ç»™å®šçš„ä¸€ç¯‡è®ºæ–‡æ˜¯å¦å€¼å¾—æ¨èç»™ç”¨æˆ·ã€‚
    
    ã€ç”¨æˆ·ç ”ç©¶å…´è¶£ã€‘ï¼š
    {USER_INTEREST_DESCRIPTION}
    
    ã€è®ºæ–‡æ ‡é¢˜ã€‘ï¼š{title}
    ã€è®ºæ–‡æ‘˜è¦ã€‘ï¼š{abstract}
    
    è¯·åªå›ç­” "Yes" æˆ– "No"ã€‚å¦‚æœè®ºæ–‡çš„ä¸»é¢˜ã€æ–¹æ³•æˆ–æ ¸å¿ƒæ¦‚å¿µä¸ç”¨æˆ·çš„å…´è¶£é«˜åº¦ç›¸å…³ï¼ˆåŒ…æ‹¬æ¦‚å¿µä¸Šçš„ç›¸å…³æ€§ï¼‰ï¼Œå›ç­” "Yes"ï¼Œå¦åˆ™å›ç­” "No"ã€‚ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–è§£é‡Šã€‚
    """

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1, # ä½æ¸©åº¦ä¿è¯å›ç­”ç¨³å®š
            max_tokens=5
        )
        answer = response.choices[0].message.content.strip().lower()
        return "yes" in answer
    except Exception as e:
        print(f"AI Check Error: {e}")
        # å¦‚æœAIæŠ¥é”™ï¼ˆæ¯”å¦‚ç½‘ç»œé—®é¢˜ï¼‰ï¼Œé»˜è®¤æ”¾è¡Œæˆ–è€…è®¾ä¸ºFalseï¼Œè¿™é‡Œè®¾ä¸ºFalseé˜²æ­¢ä¹±å‘
        return False

def clean_html_text(raw_html):
    if not raw_html: return ""
    soup = BeautifulSoup(raw_html, "html.parser")
    text = soup.get_text(separator=' ')
    return ' '.join(text.split())

def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS articles
                 (link TEXT PRIMARY KEY, title TEXT, journal TEXT, published_date TEXT)''')
    conn.commit()
    conn.close()

def is_article_new(link):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT 1 FROM articles WHERE link=?", (link,))
    exists = c.fetchone()
    conn.close()
    return exists is None

def save_article(link, title, journal, pub_date):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT OR IGNORE INTO articles VALUES (?, ?, ?, ?)", (link, title, journal, pub_date))
    conn.commit()
    conn.close()

def send_html_email(subject, html_content):
    if not SENDER_EMAIL or not SENDER_PASSWORD:
        return False
    msg = MIMEText(html_content, 'html', 'utf-8')
    msg['From'] = Header(SENDER_EMAIL)
    msg['To'] = Header(RECEIVER_EMAIL)
    msg['Subject'] = Header(subject, 'utf-8')
    try:
        server = smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT)
        server.login(SENDER_EMAIL, SENDER_PASSWORD)
        server.sendmail(SENDER_EMAIL, [RECEIVER_EMAIL], msg.as_string())
        server.quit()
        print("Email sent successfully.")
        return True
    except Exception as e:
        print(f"Email Error: {e}")
        return False

def run_job():
    print(f"[{datetime.now()}] Job started...")
    
    monthly_data = {}
    total_new_count = 0
    interesting_count = 0
    pending_save_list = []

    for journal_name, rss_url in RSS_FEEDS.items():
        print(f"Checking {journal_name}...")
        try:
            feed = feedparser.parse(rss_url)
            if not feed.entries: continue

            # ä¸ºäº†èŠ‚çœTokenå’Œæ—¶é—´ï¼Œé™åˆ¶æ¯æ¬¡æœ€å¤šæ£€æŸ¥å‰30ç¯‡
            for entry in feed.entries[:30]: 
                title = entry.title
                link = entry.link
                pub_date = entry.get('published', datetime.now().strftime('%Y-%m-%d'))
                
                # åªæœ‰å½“æ–‡ç« æ˜¯æ–°çš„æ‰å»è°ƒç”¨AIæ£€æŸ¥ï¼ˆçœé’±ã€çœæ—¶é—´ï¼‰
                if is_article_new(link):
                    raw_summary = entry.get('summary') or entry.get('description') or ""
                    clean_summary = clean_html_text(raw_summary)

                    # === è°ƒç”¨ AI è¿›è¡Œæ™ºèƒ½åˆ¤æ–­ ===
                    # æ‰“å°ä¸€ä¸‹æ­£åœ¨æ£€æŸ¥å“ªç¯‡ï¼Œæ–¹ä¾¿åœ¨ GitHub Log é‡Œçœ‹
                    print(f"Analyzing with AI: {title[:50]}...") 
                    is_interesting = get_ai_judgement(title, clean_summary)
                    time.sleep(0.2) # ç¨å¾®æ­‡ä¸€ä¸‹ï¼Œé˜²æ­¢APIé€Ÿç‡é™åˆ¶
                    
                    if journal_name not in monthly_data:
                        monthly_data[journal_name] = []
                    
                    article_info = {
                        "title": title,
                        "link": link,
                        "date": pub_date,
                        "journal": journal_name,
                        "summary": clean_summary,
                        "is_interesting": is_interesting
                    }
                    
                    if is_interesting:
                        monthly_data[journal_name].insert(0, article_info)
                        interesting_count += 1
                        print(f"  >>> MATCH FOUND: {title[:30]}")
                    else:
                        monthly_data[journal_name].append(article_info)
                        
                    pending_save_list.append(article_info)
                    total_new_count += 1
        except Exception as e:
            print(f"Error checking {journal_name}: {e}")

    if total_new_count > 0:
        print(f"Found {total_new_count} new articles ({interesting_count} AI-Matched).")
        
        subject_prefix = "ğŸ¤– " if interesting_count > 0 else ""
        
        html_body = f"""
        <html>
        <body style="font-family: Arial, sans-serif;">
            <h2 style="color: #2c3e50;">ğŸ“… é‡‘èé¡¶åˆŠ AI ç­›é€‰æ±‡æ€»</h2>
            <p>æœ¬æ¬¡æ›´æ–° <b>{total_new_count}</b> ç¯‡æ–‡ç« ï¼ŒAI åŠ©æ‰‹ä¸ºæ‚¨è¯†åˆ«å‡º <b>{interesting_count}</b> ç¯‡ç›¸å…³æ–‡ç« ã€‚</p>
            <div style="background-color: #e8f4fd; padding: 10px; border-radius: 5px; color: #555; font-size: 0.9em; margin-bottom: 20px;">
                <b>æ‚¨çš„ç­›é€‰æ ‡å‡†:</b><br>{USER_INTEREST_DESCRIPTION.replace(chr(10), '<br>')}
            </div>
            <hr>
        """
        
        for journal, articles in monthly_data.items():
            html_body += f"<h3 style='background-color: #f2f2f2; padding: 10px; border-left: 5px solid #0066cc;'>ğŸ“š {journal} ({len(articles)}ç¯‡)</h3><ul>"
            for art in articles:
                if art['is_interesting']:
                    icon = "ğŸ’¡" # AI æ¨èçš„å›¾æ ‡
                    title_style = "color: #d35400; font-weight: bold; font-size: 1.1em;"
                    # AI æ¨èçš„æ–‡ç« ï¼Œæ˜¾ç¤ºæ‘˜è¦
                    summary_html = f"<div style='background-color: #fff8f0; padding: 10px; margin-top: 5px; border-radius: 5px; color: #444; font-size: 0.9em; line-height: 1.5;'>{art['summary'][:600]}...</div>"
                else:
                    icon = ""
                    title_style = "color: #0066cc; font-weight: bold;"
                    summary_html = "" # æ™®é€šæ–‡ç« ä¸æ˜¾ç¤ºæ‘˜è¦

                html_body += f"""
                <li style="margin-bottom: 20px;">
                    {icon} <a href="{art['link']}" style="{title_style} text-decoration: none;">{art['title']}</a>
                    <span style="color: #999; font-size: 0.85em; margin-left: 10px;">{art['date']}</span>
                    {summary_html}
                </li>
                """
            html_body += "</ul>"
        
        html_body += "</body></html>"
        
        if send_html_email(f"{subject_prefix}AIç²¾é€‰é¡¶åˆŠ: {interesting_count}/{total_new_count}ç¯‡", html_body):
            print("Saving to DB...")
            for art in pending_save_list:
                save_article(art['link'], art['title'], art['journal'], art['date'])
    else:
        print("No new articles.")

if __name__ == "__main__":
    init_db()
    run_job()
